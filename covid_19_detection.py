# -*- coding: utf-8 -*-
"""COVID - 19 Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GmfeU8AJhPdOa2ODD8Ww6fcYo5WCO_6x

# **Fetch, Load and Draw Insights from Data**
"""

# Clone the repository that contains data
!git clone https://github.com/ieee8023/covid-chestxray-dataset.git

# Read data as pandas dataframe
import pandas as pd
import pickle as pkl

metadata = pd.read_csv("covid-chestxray-dataset/metadata.csv")
metadata = metadata.drop(["Unnamed: 29", "patientid", "temperature", "pO2_saturation", "leukocyte_count", "survival", "neutrophil_count", "lymphocyte_count", "modality", "date", "location", "folder", "doi", "url", "license", "extubated", "other_notes"], axis=1)
# metadata.head()

# Analyse what different types of diseases are present
# metadata["finding"].unique()

"""# **Preprocess Data**"""

# Add a new column "label" containing the label 1 if finding is "Pneumonia/Viral/COVID-19" else 0
possible_labels = metadata.finding.unique()
labels_dict = {possible_label: (1 if possible_label == "Pneumonia/Viral/COVID-19" else 0) for possible_label in possible_labels}
metadata["label"] = metadata.finding.replace(labels_dict)
# metadata.head()

# Change the finding "Pneumonia/Viral/COVID-19" to "COVID-19"
covid_metadata = metadata.replace(to_replace="Pneumonia/Viral/COVID-19", value="COVID-19")
# covid_metadata.head()

"""# **Generate Image Embeddings**
I've used state-of-the-art EfficientNetB7 architecture for generating image embeddings.
"""

# If you already have image embeddings, load them and skip the execution of next cell
print("Loading image embeddings...")
image_embeddings = pkl.load(open('image_embeddings.pkl', 'rb'))
print("Loading image embeddings done!\n")

from tensorflow.keras.models import Model
from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input

# Load the model
# model = EfficientNetB7(include_top=True)
# new_model = Model(inputs=model.input, outputs=model.layers[-3].output)
# print("Model for generating image embeddings:")
# print(new_model.summary())


# Generate image embeddings
# import cv2
import os
from tqdm import tqdm

# image_embeddings = list()
# image_series = covid_metadata.filename

# c = 0
# for image_name in tqdm(image_series):
#   try:
#     image = cv2.imread("covid-chestxray-dataset/images/" + image_name)
#     image = cv2.resize(image, (600, 600))
#     image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
#     image = preprocess_input(image)
#     image_embedding = new_model.predict(image)
#     image_embeddings.append(image_embedding[0])
#   except:
#     c += 1
#     image_embeddings.append(None)

# pkl.dump(image_embeddings, open('image_embeddings.pkl', 'wb'))

# print(f"\nFailed to generate image embeddings for {c} images.")

# Add image embeddings as a new column to dataframe
covid_metadata['image_embeddings'] = image_embeddings
# covid_metadata.head()

# Drop samples whose image embeddings are None
print(f"Shape without removing null image embeddings: {covid_metadata.shape}")
covid_metadata = covid_metadata.dropna(axis=0, subset=['image_embeddings'])
print(f"Shape after removing null image embeddings: {covid_metadata.shape}")

"""# **Generate Text Embeddings (Clinical Notes Embeddings)**
Even clinical notes are important for drawing inferences about a patien't condition. We cannot neglect them. So I've used BioSentVec model, which is specifically trained on a very huge corpus of medical data, to convert these clinical notes into numbers and generate text embeddings. 
"""

# If you already have text_embeddings, load them and skip the execution of next cell
print("Loading text embeddings...")
text_embeddings = pkl.load(open('text_embeddings.pkl', 'rb'))
print("Loading text embeddings done!")

# Commented out IPython magic to ensure Python compatibility.
# Download BioSentVec model for generating clinical notes embeddings
# !wget https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioSentVec_PubMed_MIMICIII-bigram_d700.bin

# Install sent2vec required for loading BioSentVec model
# !wget https://github.com/epfml/sent2vec/archive/master.zip
# !unzip master.zip
# %cd sent2vec-master
# !make
# !sudo pip install .

# Load BioSentVec model
# import sent2vec

# model = sent2vec.Sent2vecModel()
# model.load_model('BioSentVec_PubMed_MIMICIII-bigram_d700.bin')

# Generate text embeddings
# text_embeddings = list()
# text_series = covid_metadata.clinical_notes

# c = 0
# for clinical_data in text_series:
#   try:
#     text_embedding = model.embed_sentence(clinical_data)
#     text_embeddings.append(text_embedding[0])
#   except:
#     c += 1
#     text_embeddings.append(model.embed_sentence("No clinical notes are available for this patient.")[0])

# pkl.dump(text_embeddings, open('text_embeddings.pkl', 'wb'))
# print(f"\nFailed to generate text embeddings for {c} texts.")

# Add text embeddings as a new column to the dataframe
covid_metadata['text_embeddings'] = text_embeddings
# covid_metadata.head()

"""# **Deal with Missing in Features** 
For offset and age feature, I've replaced the missing values with the most occurrring value as it shows the general trend of most of patient admitted.  

And for rest all other features, I've replaced missing values with a tag 'Unclear'.
"""

# Deal with null values present in columns by replacing null value with 'Unclear' string except in case of age and 
# offset where null values are replaced withthe mode of columns
covid_metadata.age = covid_metadata.age.fillna(covid_metadata['age'].value_counts().max())
covid_metadata.offset = covid_metadata.offset.fillna(covid_metadata['offset'].value_counts().max())
covid_metadata.sex = covid_metadata.sex.fillna('Unclear')
covid_metadata.RT_PCR_positive = covid_metadata.RT_PCR_positive.fillna('N')
covid_metadata.intubated = covid_metadata.intubated.fillna('Unclear')
covid_metadata.intubation_present = covid_metadata.intubation_present.fillna('Unclear')
covid_metadata.in_icu = covid_metadata.in_icu.fillna('Unclear')
covid_metadata.went_icu = covid_metadata.went_icu.fillna('Unclear')
covid_metadata.needed_supplemental_O2 = covid_metadata.needed_supplemental_O2.fillna('Unclear')
# covid_metadata.head()

"""# **Transform Age feature into Categorical feature**:
I've transformed age feature into a categorical feature. This is because ages like 23, 24 or 25 won't make much difference. So I've divided them into appropriate bins.
"""

# Divide age into bins
covid_metadata.age = pd.cut(x=covid_metadata['age'], bins=[18, 28, 33, 38, 43, 48, 53, 58, 63, 68, 100], labels=[23, 30, 35, 40, 45, 50, 55, 60, 65, 70])
# covid_metadata.head()

"""# **One-Hot Encode Categorical Features** """

# For encoding categorical data, install category_encoders
!pip install category_encoders

import category_encoders as ce

encoder = ce.OneHotEncoder(cols=['sex', 'age', 'RT_PCR_positive', 'intubated', 'intubation_present', 'went_icu', 'in_icu', 'needed_supplemental_O2', 'view'], handle_unknown='return_nan', return_df=True, use_cat_names=True)
covid_metadata = encoder.fit_transform(covid_metadata)
# covid_metadata.head()

# covid_metadata.info()

"""# **Random Forest Classifiers**"""

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

test_size = 0.15
random_state_split = 16
random_state_classifier = 0

"""## Random Forest Classifeir for Image Embeddings:"""
print("Training random forest classifier for image embeddings...")
# Load data
X = covid_metadata.image_embeddings
y = covid_metadata.label

# X.head()

# y.head()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state_split)

print("Shape of original dataset :", covid_metadata.shape)
print("Shape of input - training set", X_train.shape)
print("Shape of output - training set", y_train.shape)
print("Shape of input - testing set", X_test.shape)
print("Shape of output - testing set", y_test.shape)

# Prepare data
tX_train = list()
for i in X_train:
  tX_train.append(list(i))
tX_train = np.array(tX_train)  


tX_test = list()
for i in X_test:
  tX_test.append(list(i))
tX_test = np.array(tX_test)


ty_train = list()
for i in y_train:
  ty_train.append(i)
ty_train = np.array(ty_train)


ty_test = list()
for i in y_test:
  ty_test.append(i)
ty_test = np.array(ty_test)

# Train classifier
clf_image = RandomForestClassifier(n_estimators=100, random_state=random_state_classifier)
clf_image.fit(tX_train, ty_train)

# Predict using classifier
y_pred_image = clf_image.predict(tX_test)
acc = sum(y_pred_image  == ty_test)/len(tX_test) * 100
print("Training done for random forest classifier for image embeddings.")
print(f"Valdiation set accuracy for image classifier: {str(acc)[:5]}")

"""## Random Forest Classifier for Clinical Notes (Text Embeddings)"""
print("Training random forest classifier for text embeddings...")
# Load data
X = covid_metadata.text_embeddings
y = covid_metadata.label

# X.head()

# y.head()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state_split)

print("Shape of original dataset :", covid_metadata.shape)
print("Shape of input - training set", X_train.shape)
print("Shape of output - training set", y_train.shape)
print("Shape of input - testing set", X_test.shape)
print("Shape of output - testing set", y_test.shape)

# Prepare data
tX_train = list()
for i in X_train:
  tX_train.append(list(i))
tX_train = np.array(tX_train)


tX_test = list()
for i in X_test:
  tX_test.append(list(i))
tX_test = np.array(tX_test)


ty_train = list()
for i in y_train:
  ty_train.append(i)
ty_train = np.array(ty_train)


ty_test = list()
for i in y_test:
  ty_test.append(i)
ty_test = np.array(ty_test)

# Train classifier
clf_text = RandomForestClassifier(random_state=random_state_classifier)
clf_text.fit(tX_train, ty_train)

# Predict using classifier
y_pred_text = clf_text.predict(tX_test)
acc = sum(y_pred_text  == ty_test)/len(tX_test) * 100
print("Training done for random forest classifier for text embeddings.")
print(f"Valdiation set accuracy: {str(acc)[:5]}%.")

"""## Random Forest Classifier for Patient Features"""
print("Training random forest classifier for patient features...")
# Load data
y = covid_metadata.label
X = covid_metadata.drop(["finding", "filename", "clinical_notes", "label", "image_embeddings", "text_embeddings"], axis=1)

X.head()

y.head()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state_split)

print("Shape of original dataset :", covid_metadata.shape)
print("Shape of input - training set", X_train.shape)
print("Shape of output - training set", y_train.shape)
print("Shape of input - testing set", X_test.shape)
print("Shape of output - testing set", y_test.shape)

# Train classifier
clf_features = RandomForestClassifier(random_state=random_state_classifier)
clf_features.fit(X_train, y_train)

# Predict using classifier
y_pred_features = clf_features.predict(X_test)
acc = sum(y_pred_features  == y_test)/len(X_test) * 100
print("Training done for random forest classifier for patient features.")
print(f"Valdiation set accuracy: {str(acc)[:5]}")

"""# **Calculating Resultant Accuracy by Combining the predictions of each classifier**"""
print("Combining the three classifiers")
def covid_19_detection(y_pred_image, y_pred_text, y_pred_features):
  res = list()
  for i, j, k in zip(y_pred_image, y_pred_text, y_pred_features):
    if (i+j+k) >= 2:
      res.append(1)
    else:
      res.append(0)

  return res

y_pred = covid_19_detection(y_pred_image, y_pred_text, y_pred_features)

res_acc = sum(y_pred == y_test)/len(y_test) * 100
print(f"Resultant validation accuracy is: {str(res_acc)[:5]}%.")
